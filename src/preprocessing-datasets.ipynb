{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from geopy.distance import great_circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSTANTI\n",
    "\n",
    "# dizionario che mappa i nomi dei borough ai loro acronimi\n",
    "ACRONYMS = {'BRONX': 'BX',\n",
    "            'BROOKLYN': 'BK',\n",
    "            'MANHATTAN': 'MN',\n",
    "            'QUEENS': 'QN',\n",
    "            'STATEN ISLAND': 'SI'}\n",
    "\n",
    "# dizionario che mappa i codici dei distretti alle sub-borough area\n",
    "DISTRICTS_MAP = {'BK01': 'Williamsburg/Greenpoint',\n",
    "                 'BK02': 'Brooklyn Heights/Fort Greene',\n",
    "                 'BK03': 'Bedford Stuyvesant',\n",
    "                 'BK04': 'Bushwick',\n",
    "                 'BK05': 'East New York/Starrett City',\n",
    "                 'BK06': 'Park Slope/Carroll Gardens',\n",
    "                 'BK07': 'Sunset Park',\n",
    "                 'BK08': 'North Crown Heights/Prospect Heights',\n",
    "                 'BK09': 'South Crown Heights',\n",
    "                 'BK10': 'Bay Ridge',\n",
    "                 'BK11': 'Bensonhurst',\n",
    "                 'BK12': 'Borough Park',\n",
    "                 'BK13': 'Coney Island',\n",
    "                 'BK14': 'Flatbush',\n",
    "                 'BK15': 'Sheepshead Bay/Gravesend',\n",
    "                 'BK16': 'Brownsville/Ocean Hill',\n",
    "                 'BK17': 'East Flatbush',\n",
    "                 'BK18': 'Flatlands/Canarsie',\n",
    "                 'BX01': 'Mott Haven/Hunts Point',\n",
    "                 'BX02': 'Mott Haven/Hunts Point',\n",
    "                 'BX03': 'Morrisania/Belmont',\n",
    "                 'BX04': 'Highbridge/South Concourse',\n",
    "                 'BX05': 'University Heights/Fordham',\n",
    "                 'BX06': 'Morrisania/Belmont',\n",
    "                 'BX07': 'Kingsbridge Heights/Mosholu',\n",
    "                 'BX08': 'Riverdale/Kingsbridge',\n",
    "                 'BX09': 'Soundview/Parkchester',\n",
    "                 'BX10': 'Throgs Neck/Co-op City',\n",
    "                 'BX11': 'Pelham Parkway',\n",
    "                 'BX12': 'Williamsbridge/Baychester',\n",
    "                 'MN01': 'Greenwich Village/Financial District',\n",
    "                 'MN02': 'Greenwich Village/Financial District',\n",
    "                 'MN03': 'Lower East Side/Chinatown',\n",
    "                 'MN04': 'Chelsea/Clinton/Midtown',\n",
    "                 'MN05': 'Chelsea/Clinton/Midtown',\n",
    "                 'MN06': 'Stuyvesant Town/Turtle Bay',\n",
    "                 'MN07': 'Upper West Side',\n",
    "                 'MN08': 'Upper East Side',\n",
    "                 'MN09': 'Morningside Heights/Hamilton Heights',\n",
    "                 'MN10': 'Central Harlem',\n",
    "                 'MN11': 'East Harlem',\n",
    "                 'MN12': 'Washington Heights/Inwood',\n",
    "                 'QN01': 'Astoria',\n",
    "                 'QN02': 'Sunnyside/Woodside',\n",
    "                 'QN03': 'Jackson Heights',\n",
    "                 'QN04': 'Elmhurst/Corona',\n",
    "                 'QN05': 'Middle Village/Ridgewood',\n",
    "                 'QN06': 'Rego Park/Forest Hills',\n",
    "                 'QN07': 'Flushing/Whitestone',\n",
    "                 'QN08': 'Hillcrest/Fresh Meadows',\n",
    "                 'QN09': 'Ozone Park/Woodhaven',\n",
    "                 'QN10': 'South Ozone Park/Howard Beach',\n",
    "                 'QN11': 'Bayside/Little Neck',\n",
    "                 'QN12': 'Jamaica',\n",
    "                 'QN13': 'Queens Village',\n",
    "                 'QN14': 'Rockaways',\n",
    "                 'SI01': 'North Shore',\n",
    "                 'SI02': 'Mid-Island',\n",
    "                 'SI03': 'South Shore'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING DEL DATASET SULLE `REQUESTS`\n",
    "\n",
    "def preprocess_requests_data():\n",
    "    \"\"\"\n",
    "    Esegue il preprocessing iniziale del dataset '311-2023-05.csv',\n",
    "    ottenuto precedentemente dalla selezione delle richieste di servizio 311\n",
    "    fatte nel mese di maggio dell'anno 2023, da cui sono state inoltre\n",
    "    eliminate colonne a valori per la maggior parte nulli.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('datasets/311-2023-05.csv')\n",
    "\n",
    "    cols_to_normalize = ['Complaint Type', 'Descriptor', 'Incident Address',\n",
    "                         'Location Type', 'Borough', 'Status', 'Open Data Channel Type']\n",
    "    \n",
    "    normalize_string_spaces = lambda s: ' '.join(s.split())\n",
    "    def transform_district_codes(s):\n",
    "        number, borough = s.split(' ', 1)\n",
    "        return f\"{ACRONYMS.get(borough)}{number}\"\n",
    "    \n",
    "    df.drop(columns=['Street Name', 'Vehicle Type', 'Taxi Company Borough'], inplace=True)\n",
    "    df.rename(columns={'Community Board': 'Sub-Borough Area'}, inplace=True)\n",
    "\n",
    "    df = df.dropna(subset=['Location'])\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].fillna('unknown')\n",
    "    \n",
    "    for col in cols_to_normalize:\n",
    "        df[col] = df[col].apply(normalize_string_spaces)\n",
    "        df[col] = df[col].str.lower()\n",
    "    \n",
    "    df['Sub-Borough Area'] = df['Sub-Borough Area'].apply(transform_district_codes).map(DISTRICTS_MAP).str.lower()\n",
    "\n",
    "    df[['Latitude', 'Longitude']] = df['Location'].str.extract(r'\\(([^,]+), ([^,]+)\\)').astype(float)\n",
    "    df.drop(columns=['Location'], inplace=True)\n",
    "\n",
    "    df.to_csv('datasets/311-2023-05-v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steag\\AppData\\Local\\Temp\\ipykernel_18132\\1782791959.py:10: DtypeWarning: Columns (13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('datasets/311-2023-05.csv')\n"
     ]
    }
   ],
   "source": [
    "preprocess_requests_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSTANTI\n",
    "\n",
    "# lista dei path dei dataset sui distretti\n",
    "DISTRICTS_DATA_PATHS = ['datasets/district-incomedistribution.csv',\n",
    "                        'datasets/district-povertyrate.csv',\n",
    "                        'datasets/district-racecomposition.csv',\n",
    "                        'datasets/district-crimerate.csv']\n",
    "\n",
    "# lista delle coppie di distretti i cui dati sono ripetuti\n",
    "DISTRICTS_TO_COLLAPSE = [('BX01', 'BX02'),\n",
    "                         ('BX03', 'BX06'),\n",
    "                         ('MN01', 'MN02'),\n",
    "                         ('MN04', 'MN05')]\n",
    "\n",
    "# lista delle coppie (path, rinominazione della colonna 2021) per ciascuno dei dataset sui sub-borough\n",
    "SUBBOROUGHS_DATA_INFO = [('datasets/sub-borougharea-populationdensity1000personspersquaremile.csv', 'Population Density'),\n",
    "                         ('datasets/sub-borougharea-populationaged65.csv', 'Population Aged 65+'),\n",
    "                         ('datasets/sub-borougharea-borninnewyorkstate.csv', 'NYS Born People'),\n",
    "                         ('datasets/sub-borougharea-foreign-bornpopulation.csv', 'Foreign Born People'),\n",
    "                         ('datasets/sub-borougharea-disabledpopulation.csv', 'Disabled People'),\n",
    "                         ('datasets/sub-borougharea-unemploymentrate.csv', 'Unemployment Rate'),\n",
    "                         ('datasets/sub-borougharea-car-freecommuteofcommuters.csv', 'Car-Free Commuters'),\n",
    "                         ('datasets/sub-borougharea-householdswithchildrenunder18yearsold.csv', 'Families with Children'),\n",
    "                         ('datasets/sub-borougharea-populationaged25withabachelorsdegreeorhigher.csv', 'People O25 with Bachelor'),\n",
    "                         ('datasets/sub-borougharea-populationaged25withoutahighschooldiploma.csv', 'People O25 without Diploma')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING DEL DATASET SUI `SUBBOROUGHS`\n",
    "\n",
    "def preprocess_subboroughs_data():\n",
    "    \"\"\"\n",
    "    Esegue il preprocessing dei dataset sulle sub-borough area,\n",
    "    ognuno contenente uno o pi√π attributi di interesse. I dataset\n",
    "    sono poi joinati tra loro per ottenere un unico dataset sui sub-boroughs.\n",
    "    \"\"\"\n",
    "    df_incomedistribution = pd.read_csv(DISTRICTS_DATA_PATHS[0])\n",
    "    df_povertyrate = pd.read_csv(DISTRICTS_DATA_PATHS[1])\n",
    "    df_racecomposition = pd.read_csv(DISTRICTS_DATA_PATHS[2])\n",
    "    df_crimerate = pd.read_csv(DISTRICTS_DATA_PATHS[3])\n",
    "\n",
    "    df_incomedistribution.rename(columns={'year': 'Year'}, inplace=True)\n",
    "    df_incomedistribution = df_incomedistribution[df_incomedistribution['Year'] == '2018-2022']\n",
    "\n",
    "    def process_districts_data(df, cols_to_drop, rename_columns):\n",
    "        df = df.copy()\n",
    "        df = df.iloc[6:]\n",
    "        df.drop(columns=cols_to_drop, inplace=True)\n",
    "        df.rename(columns={'Geography': 'Community District'}, inplace=True)\n",
    "        df['Community District'] = df['Community District'].apply(lambda s: ''.join(s.split()))\n",
    "        df.rename(columns=rename_columns, inplace=True)\n",
    "        return df\n",
    "    \n",
    "    cols_to_drop = ['Name', 'Level', 'Year']\n",
    "    df_crimerate = process_districts_data(df_crimerate, cols_to_drop, {'property_crime_rate': 'Property Crime Rate',\n",
    "                                                                         'violent_crime_rate': 'Violent Crime Rate'})\n",
    "    df_incomedistribution = process_districts_data(df_incomedistribution, cols_to_drop, {'<=$20,000': 'Low Income Population',\n",
    "                                                                                           '$20,001-$40,000': 'Medium-Low Income Population',\n",
    "                                                                                           '$40,001-$60,000': 'Medium Income Population',\n",
    "                                                                                           '$60,001-$100,000': 'Medium-High Income Population',\n",
    "                                                                                           '$100,001-$250,000': 'High Income Population',\n",
    "                                                                                           '>$250,000': 'Very High Income Population'})\n",
    "    df_povertyrate = process_districts_data(df_povertyrate, cols_to_drop, {'poverty_rate': 'Poverty Rate'})\n",
    "    df_racecomposition = process_districts_data(df_racecomposition, cols_to_drop, {'pop_hispanic_pct': 'Hispanic Population',\n",
    "                                                                                     'pop_non_hispanic_asian_pct': 'Asian Population',\n",
    "                                                                                     'pop_non_hispanic_black_pct': 'Black Population',\n",
    "                                                                                     'pop_non_hispanic_white_pct': 'White Population'})\n",
    "    \n",
    "    df_join = pd.merge(df_crimerate, df_incomedistribution, on='Community District', how='inner')\n",
    "    df_join = pd.merge(df_join, df_povertyrate, on='Community District', how='inner')\n",
    "    df_join = pd.merge(df_join, df_racecomposition, on='Community District', how='inner')\n",
    "\n",
    "    for i, col in enumerate(df_join.columns):\n",
    "        if i > 2:\n",
    "            df_join[col] = df_join[col].str.replace('%', '').astype(float)\n",
    "    \n",
    "    col_pc, col_vc = 'Property Crime Rate', 'Violent Crime Rate'\n",
    "    for dist in DISTRICTS_TO_COLLAPSE:\n",
    "        cond1, cond2 = df_join['Community District'] == dist[0], df_join['Community District'] == dist[1]\n",
    "\n",
    "        new_pc = (df_join.loc[cond1, col_pc].values[0] + df_join.loc[cond2, col_pc].values[0]) / 2\n",
    "        new_vc = (df_join.loc[cond1, col_vc].values[0] + df_join.loc[cond2, col_vc].values[0]) / 2\n",
    "        df_join.loc[cond1 | cond2, col_pc] = round(new_pc, 2)\n",
    "        df_join.loc[cond1 | cond2, col_vc] = round(new_vc, 2)\n",
    "    \n",
    "    df_join['Community District'] = df_join['Community District'].map(DISTRICTS_MAP)\n",
    "    df_join.rename(columns={'Community District': 'Sub-Borough Area'}, inplace=True)\n",
    "    df_join = df_join.drop_duplicates()\n",
    "\n",
    "    cols_to_drop = [str(year) for year in range(2000, 2021)]\n",
    "    cols_to_drop.extend(['short_name', 'long_name'])\n",
    "\n",
    "    for info in SUBBOROUGHS_DATA_INFO:\n",
    "        df = pd.read_csv(info[0])\n",
    "        df.drop(columns=cols_to_drop, errors='ignore', inplace=True)\n",
    "        df.rename(columns={'2021': info[1]}, inplace=True)\n",
    "        df_join = pd.merge(df_join, df, on='Sub-Borough Area', how='inner')\n",
    "    \n",
    "    subboroughs_cols = [col[1] for col in SUBBOROUGHS_DATA_INFO]\n",
    "    for i, col in enumerate(subboroughs_cols):\n",
    "        if i > 1:\n",
    "            df_join[col] = df_join[col].astype(float) * 100\n",
    "        df_join[col] = df_join[col].round(2)\n",
    "    \n",
    "    df_join['Sub-Borough Area'] = df_join['Sub-Borough Area'].str.lower()\n",
    "    df_join.to_csv('datasets/subboroughs-ny.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_subboroughs_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREAZIONE DEL DATASET SUGLI `INCIDENTS` UNICI\n",
    "\n",
    "def create_incidents_dataset():\n",
    "    \"\"\"\n",
    "    Individua, a partire dal dataset preprocessato '311-2023-05-v2.csv',\n",
    "    gli incidents unici oggetto di pi√π richieste, isolandoli e\n",
    "    definendo un dataset che li collezioni.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('datasets/311-2023-05-v2.csv')\n",
    "\n",
    "    def is_same_incident(row1, row2, time_window_hours=24, space_window_meters=100):\n",
    "        time_diff = abs((row1['Created Date'] - row2['Created Date']).total_seconds()) / 3600\n",
    "        if time_diff > time_window_hours:\n",
    "            return False\n",
    "        \n",
    "        distance = great_circle((row1['Latitude'], row1['Longitude']), (row2['Latitude'], row2['Longitude'])).meters\n",
    "        if distance > space_window_meters:\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def identify_incidents(df):\n",
    "        incidents = []\n",
    "        used_indexes = set()\n",
    "\n",
    "        z = 0\n",
    "        for i, row1 in df.iterrows():\n",
    "            if i in used_indexes:\n",
    "                continue\n",
    "            incident = [i]\n",
    "            for j, row2 in df.iterrows():\n",
    "                if j != i and j not in used_indexes and is_same_incident(row1, row2):\n",
    "                    incident.append(j)\n",
    "            used_indexes.update(incident)\n",
    "            incidents.append(incident)\n",
    "            z += 1\n",
    "            print(f\"{round(z/len(df), 3)}\")\n",
    "        return incidents\n",
    "    \n",
    "    df['Created Date'] = pd.to_datetime(df['Created Date'])\n",
    "    groups = df.groupby(['Complaint Type', 'Descriptor', 'Location Type'])\n",
    "    unique_incidents = []\n",
    "\n",
    "    tot = 0\n",
    "    for _, df_group in groups:\n",
    "        tot += len(df_group)\n",
    "        new_incidents = identify_incidents(df_group)\n",
    "        unique_incidents.extend(new_incidents)\n",
    "        print(f\"--> {round(tot/len(df), 3)}\")\n",
    "    \n",
    "    df['Incident Id'] = 0\n",
    "    incidents_rows = []\n",
    "    for i, incident in enumerate(unique_incidents):\n",
    "        incident_id = i + 1\n",
    "        df.loc[incident, 'Incident Id'] = incident_id\n",
    "        row = df.iloc[incident].iloc[0]\n",
    "        incident_row = {'Id': incident_id,\n",
    "                        'Occurence Date': df.iloc[incident]['Created Date'].min(),\n",
    "                        'Complaint Type': row['Complaint Type'],\n",
    "                        'Location Type': row['Location Type'],\n",
    "                        'Address': row['Address'],\n",
    "                        'Borough': row['Borough'],\n",
    "                        'Sub-Borough Area': row['Sub-Borough Area']}\n",
    "        incidents_rows.append(incident_row)\n",
    "    \n",
    "    df_incidents = pd.DataFrame(incidents_rows)\n",
    "    df_incidents.to_csv('datasets/unique-incidents.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_incidents_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
